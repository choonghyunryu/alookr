<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Classification Modeling • alookr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/united/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Classification Modeling">
<meta property="og:description" content="alookr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">alookr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.3.4</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../articles/cleansing.html">Cleansing the dataset</a>
</li>
<li>
  <a href="../articles/split.html">Splitting the dataset</a>
</li>
<li>
  <a href="../articles/modeling.html">Classification Modeling</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="../reference/index.html">Function reference</a>
</li>
<li>
  <a href="https://github.com/choonghyunryu/alookr/">
    <span class="fas fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="modeling_files/header-attrs-2.6.4/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Classification Modeling</h1>
                        <h4 class="author">Choonghyun Ryu</h4>
            
            <h4 class="date">2021-02-21</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/choonghyunryu/alookr/blob/master/vignettes/modeling.Rmd"><code>vignettes/modeling.Rmd</code></a></small>
      <div class="hidden name"><code>modeling.Rmd</code></div>

    </div>

    
    
<div id="preface" class="section level2">
<h2 class="hasAnchor">
<a href="#preface" class="anchor"></a>Preface</h2>
<p>Once the data set is ready for model development, the model is fitted, predicted and evaluated in the following ways:</p>
<ul>
<li>Cleansing the dataset</li>
<li>Split the data into a train set and a test set</li>
<li>
<strong>Modeling and Evaluate, Predict</strong>
<ul>
<li>
<strong>Modeling</strong>
<ul>
<li><strong>Binary classification modeling</strong></li>
</ul>
</li>
<li>
<strong>Evaluate the model</strong>
<ul>
<li><strong>Predict test set using fitted model</strong></li>
<li><strong>Calculate the performance metric</strong></li>
<li><strong>Plot the ROC curve</strong></li>
<li>
<strong>Tunning the cut-off</strong><br>
</li>
</ul>
</li>
<li>
<strong>Predict</strong>
<ul>
<li><strong>Predict</strong></li>
<li><strong>Predict with cut-off</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The alookr package makes these steps fast and easy:</p>
</div>
<div id="data-wisconsin-breast-cancer-data" class="section level2">
<h2 class="hasAnchor">
<a href="#data-wisconsin-breast-cancer-data" class="anchor"></a>Data: Wisconsin Breast Cancer Data</h2>
<p><code>BreastCancer</code> of <code>mlbench package</code> is a breast cancer data. The objective is to identify each of a number of benign or malignant classes.</p>
<p>A data frame with 699 observations on 11 variables, one being a character variable, 9 being ordered or nominal, and 1 target class.:</p>
<ul>
<li>
<code>Id</code> : character. Sample code number</li>
<li>
<code>Cl.thickness</code> : ordered factor. Clump Thickness</li>
<li>
<code>Cell.size</code> : ordered factor. Uniformity of Cell Size</li>
<li>
<code>Cell.shape</code> : ordered factor. Uniformity of Cell Shape</li>
<li>
<code>Marg.adhesion</code> : ordered factor. Marginal Adhesion</li>
<li>
<code>Epith.c.size</code> : ordered factor. Single Epithelial Cell Size</li>
<li>
<code>Bare.nuclei</code> : factor. Bare Nuclei</li>
<li>
<code>Bl.cromatin</code> : factor. Bland Chromatin</li>
<li>
<code>Normal.nucleoli</code> : factor. Normal Nucleoli</li>
<li>
<code>Mitoses</code> : factor. Mitoses</li>
<li>
<code>Class</code> : factor. Class. level is <code>benign</code> and <code>malignant</code>.</li>
</ul>
<div class="sourceCode" id="cb1"><html><body><pre class="r">library(mlbench)
data(BreastCancer)

# class of each variables
sapply(BreastCancer, function(x) class(x)[1])
             Id    Cl.thickness       Cell.size      Cell.shape   Marg.adhesion 
    "character"       "ordered"       "ordered"       "ordered"       "ordered" 
   Epith.c.size     Bare.nuclei     Bl.cromatin Normal.nucleoli         Mitoses 
      "ordered"        "factor"        "factor"        "factor"        "factor" 
          Class 
       "factor" </pre></body></html></div>
</div>
<div id="preperation-the-data" class="section level2">
<h2 class="hasAnchor">
<a href="#preperation-the-data" class="anchor"></a>Preperation the data</h2>
<p>Perform data preprocessing as follows.:</p>
<ul>
<li>Find and imputate variables that contain missing values.</li>
<li>Split the data into a train set and a test set.</li>
<li>To solve the imbalanced class, perform sampling in the train set of raw data.</li>
<li>Cleansing the dataset for classification modeling.</li>
</ul>
<div id="fix-the-missing-value-with-dlookrimputate_na" class="section level3">
<h3 class="hasAnchor">
<a href="#fix-the-missing-value-with-dlookrimputate_na" class="anchor"></a>Fix the missing value with <code>dlookr::imputate_na()</code>
</h3>
<p>find the variables that include missing value. and imputate the missing value using imputate_na() in dlookr package.</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r">library(dlookr)
library(dplyr)

# variable that have a missing value
diagnose(BreastCancer) %&gt;%
  filter(missing_count &gt; 0)
# A tibble: 1 x 6
  variables   types  missing_count missing_percent unique_count unique_rate
  &lt;chr&gt;       &lt;chr&gt;          &lt;int&gt;           &lt;dbl&gt;        &lt;int&gt;       &lt;dbl&gt;
1 Bare.nuclei factor            16            2.29           11      0.0157

# imputation of missing value
breastCancer &lt;- BreastCancer %&gt;%
  mutate(Bare.nuclei = imputate_na(BreastCancer, Bare.nuclei, Class,
                         method = "mice", no_attrs = TRUE, print_flag = FALSE))</pre></body></html></div>
</div>
</div>
<div id="split-data-set" class="section level2">
<h2 class="hasAnchor">
<a href="#split-data-set" class="anchor"></a>Split data set</h2>
<div id="splits-the-dataset-into-a-train-set-and-a-test-set-with-split_by" class="section level3">
<h3 class="hasAnchor">
<a href="#splits-the-dataset-into-a-train-set-and-a-test-set-with-split_by" class="anchor"></a>Splits the dataset into a train set and a test set with <code>split_by()</code>
</h3>
<p><code><a href="../reference/split_by.data.frame.html">split_by()</a></code> in the alookr package splits the dataset into a train set and a test set.</p>
<p>The ratio argument of the <code><a href="../reference/split_by.data.frame.html">split_by()</a></code> function specifies the ratio of the train set.</p>
<p><code><a href="../reference/split_by.data.frame.html">split_by()</a></code> creates a class object named split_df.</p>
<div class="sourceCode" id="cb3"><html><body><pre class="r">library(alookr)

# split the data into a train set and a test set by default arguments
sb &lt;- breastCancer %&gt;%
  split_by(target = Class)

# show the class name
class(sb)
[1] "split_df"   "grouped_df" "tbl_df"     "tbl"        "data.frame"

# split the data into a train set and a test set by ratio = 0.6
tmp &lt;- breastCancer %&gt;%
  split_by(Class, ratio = 0.6)</pre></body></html></div>
<p>The <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function displays the following useful information about the split_df object:</p>
<ul>
<li>random seed : The random seed is the random seed used internally to separate the data</li>
<li>split data : Information of splited data
<ul>
<li>train set count : number of train set</li>
<li>test set count : number of test set</li>
</ul>
</li>
<li>target variable : Target variable name
<ul>
<li>minority class : name and ratio(In parentheses) of minority class</li>
<li>majority class : name and ratio(In parentheses) of majority class</li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb4"><html><body><pre class="r"># summary() display the some information
summary(sb)
** Split train/test set information **
 + random seed        :  64404 
 + split data            
    - train set count :  489 
    - test set count  :  210 
 + target variable    :  Class 
    - minority class  :  malignant (0.344778)
    - majority class  :  benign (0.655222)

# summary() display the some information
summary(tmp)
** Split train/test set information **
 + random seed        :  9860 
 + split data            
    - train set count :  419 
    - test set count  :  280 
 + target variable    :  Class 
    - minority class  :  malignant (0.344778)
    - majority class  :  benign (0.655222)</pre></body></html></div>
</div>
<div id="check-missing-levels-in-the-train-set" class="section level3">
<h3 class="hasAnchor">
<a href="#check-missing-levels-in-the-train-set" class="anchor"></a>Check missing levels in the train set</h3>
<p>In the case of categorical variables, when a train set and a test set are separated, a specific level may be missing from the train set.</p>
<p>In this case, there is no problem when fitting the model, but an error occurs when predicting with the model you created. Therefore, preprocessing is performed to avoid missing data preprocessing.</p>
<p>In the following example, fortunately, there is no categorical variable that contains the missing levels in the train set.</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="co"># list of categorical variables in the train set that contain missing levels</span>
<span class="no">nolevel_in_train</span> <span class="kw">&lt;-</span> <span class="no">sb</span> <span class="kw">%&gt;%</span>
  <span class="fu"><a href="../reference/compare_target_category.html">compare_target_category</a></span>() <span class="kw">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span>(<span class="no">train</span>)) <span class="kw">%&gt;%</span>
  <span class="fu">select</span>(<span class="no">variable</span>) <span class="kw">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span>() <span class="kw">%&gt;%</span>
  <span class="no">pull</span>

<span class="no">nolevel_in_train</span>
<span class="fu"><a href="https://rdrr.io/r/base/character.html">character</a></span>(<span class="fl">0</span>)

<span class="co"># if any of the categorical variables in the train set contain a missing level, </span>
<span class="co"># split them again.</span>
<span class="kw">while</span> (<span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="no">nolevel_in_train</span>) <span class="kw">&gt;</span> <span class="fl">0</span>) {
  <span class="no">sb</span> <span class="kw">&lt;-</span> <span class="no">breastCancer</span> <span class="kw">%&gt;%</span>
    <span class="fu"><a href="../reference/split_by.data.frame.html">split_by</a></span>(<span class="no">Class</span>)

  <span class="no">nolevel_in_train</span> <span class="kw">&lt;-</span> <span class="no">sb</span> <span class="kw">%&gt;%</span>
    <span class="fu"><a href="../reference/compare_target_category.html">compare_target_category</a></span>() <span class="kw">%&gt;%</span>
    <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span>(<span class="no">train</span>)) <span class="kw">%&gt;%</span>
    <span class="fu">select</span>(<span class="no">variable</span>) <span class="kw">%&gt;%</span>
    <span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span>() <span class="kw">%&gt;%</span>
    <span class="no">pull</span>
}</pre></body></html></div>
</div>
</div>
<div id="handling-the-imbalanced-classes-data-with-sampling_target" class="section level2">
<h2 class="hasAnchor">
<a href="#handling-the-imbalanced-classes-data-with-sampling_target" class="anchor"></a>Handling the imbalanced classes data with <code>sampling_target()</code>
</h2>
<div id="issue-of-imbalanced-classes-data" class="section level3">
<h3 class="hasAnchor">
<a href="#issue-of-imbalanced-classes-data" class="anchor"></a>Issue of imbalanced classes data</h3>
<p>Imbalanced classes(levels) data means that the number of one level of the frequency of the target variable is relatively small. In general, the proportion of positive classes is relatively small. For example, in the model of predicting spam, the class of interest spam is less than non-spam.</p>
<p>Imbalanced classes data is a common problem in machine learning classification.</p>
<p><code><a href="https://rdrr.io/r/base/table.html">table()</a></code> and <code><a href="https://rdrr.io/r/base/proportions.html">prop.table()</a></code> are traditionally useful functions for diagnosing imbalanced classes data. However, alookr’s <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> is simpler and provides more information.</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"># train set frequency table - imbalanced classes data
table(sb$Class)

   benign malignant 
      458       241 

# train set relative frequency table - imbalanced classes data
prop.table(table(sb$Class))

   benign malignant 
0.6552217 0.3447783 

# using summary function - imbalanced classes data
summary(sb)
** Split train/test set information **
 + random seed        :  64404 
 + split data            
    - train set count :  489 
    - test set count  :  210 
 + target variable    :  Class 
    - minority class  :  malignant (0.344778)
    - majority class  :  benign (0.655222)</pre></body></html></div>
</div>
<div id="handling-the-imbalanced-classes-data" class="section level3">
<h3 class="hasAnchor">
<a href="#handling-the-imbalanced-classes-data" class="anchor"></a>Handling the imbalanced classes data</h3>
<p>Most machine learning algorithms work best when the number of samples in each class are about equal. And most algorithms are designed to maximize accuracy and reduce error. So, we requre handling an imbalanced class problem.</p>
<p>sampling_target() performs sampling to solve an imbalanced classes data problem.</p>
</div>
<div id="resampling---oversample-minority-class" class="section level3">
<h3 class="hasAnchor">
<a href="#resampling---oversample-minority-class" class="anchor"></a>Resampling - oversample minority class</h3>
<p>Oversampling can be defined as adding more copies of the minority class.</p>
<p>Oversampling is performed by specifying “ubOver” in the method argument of the <code><a href="../reference/sampling_target.html">sampling_target()</a></code> function.</p>
<div class="sourceCode" id="cb7"><html><body><pre class="r"># to balanced by over sampling
train_over &lt;- sb %&gt;%
  sampling_target(method = "ubOver")

# frequency table 
table(train_over$Class)

   benign malignant 
      325       325 </pre></body></html></div>
</div>
<div id="resampling---undersample-majority-class" class="section level3">
<h3 class="hasAnchor">
<a href="#resampling---undersample-majority-class" class="anchor"></a>Resampling - undersample majority class</h3>
<p>Undersampling can be defined as removing some observations of the majority class.</p>
<p>Undersampling is performed by specifying “ubUnder” in the method argument of the <code><a href="../reference/sampling_target.html">sampling_target()</a></code> function.</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"># to balanced by under sampling
train_under &lt;- sb %&gt;%
  sampling_target(method = "ubUnder")

# frequency table 
table(train_under$Class)

   benign malignant 
      164       164 </pre></body></html></div>
</div>
<div id="generate-synthetic-samples---smote" class="section level3">
<h3 class="hasAnchor">
<a href="#generate-synthetic-samples---smote" class="anchor"></a>Generate synthetic samples - SMOTE</h3>
<p>SMOTE(Synthetic Minority Oversampling Technique) uses a nearest neighbors algorithm to generate new and synthetic data.</p>
<p>SMOTE is performed by specifying “ubSMOTE” in the method argument of the <code><a href="../reference/sampling_target.html">sampling_target()</a></code> function.</p>
<div class="sourceCode" id="cb9"><html><body><pre class="r"># to balanced by SMOTE
train_smote &lt;- sb %&gt;%
  sampling_target(seed = 1234L, method = "ubSMOTE")

# frequency table 
table(train_smote$Class)

   benign malignant 
      656       492 </pre></body></html></div>
</div>
</div>
<div id="cleansing-the-dataset-for-classification-modeling-with-cleanse" class="section level2">
<h2 class="hasAnchor">
<a href="#cleansing-the-dataset-for-classification-modeling-with-cleanse" class="anchor"></a>Cleansing the dataset for classification modeling with <code>cleanse()</code>
</h2>
<p>The <code><a href="../reference/cleanse.data.frame.html">cleanse()</a></code> cleanse the dataset for classification modeling.</p>
<p>This function is useful when fit the classification model. This function does the following.:</p>
<ul>
<li>Remove the variable with only one value.</li>
<li>And remove variables that have a unique number of values relative to the number of observations for a character or categorical variable.
<ul>
<li>In this case, it is a variable that corresponds to an identifier or an identifier.</li>
</ul>
</li>
<li>And converts the character to factor.</li>
</ul>
<p>In this example, The <code><a href="../reference/cleanse.data.frame.html">cleanse()</a></code> function removed a variable ID with a high unique rate.</p>
<div class="sourceCode" id="cb10"><html><body><pre class="r"># clean the training set
train &lt;- train_smote %&gt;%
  cleanse
── Checking unique value ─────────────────────────── unique value is one ──
No variables that unique value is one.

── Checking unique rate ─────────────────────────────── high unique rate ──
remove variables with high unique rate
● Id = 428(0.372822299651568)

── Checking character variables ─────────────────────── categorical data ──
No character variables.</pre></body></html></div>
</div>
<div id="extract-test-set-for-evaluation-of-the-model-with-extract_set" class="section level2">
<h2 class="hasAnchor">
<a href="#extract-test-set-for-evaluation-of-the-model-with-extract_set" class="anchor"></a>Extract test set for evaluation of the model with <code>extract_set()</code>
</h2>
<div class="sourceCode" id="cb11"><html><body><pre class="r"><span class="co"># extract test set</span>
<span class="no">test</span> <span class="kw">&lt;-</span> <span class="no">sb</span> <span class="kw">%&gt;%</span>
  <span class="fu"><a href="../reference/extract_set.html">extract_set</a></span>(<span class="kw">set</span> <span class="kw">=</span> <span class="st">"test"</span>)</pre></body></html></div>
</div>
<div id="binary-classification-modeling-with-run_models" class="section level2">
<h2 class="hasAnchor">
<a href="#binary-classification-modeling-with-run_models" class="anchor"></a>Binary classification modeling with <code>run_models()</code>
</h2>
<p><code><a href="../reference/run_models.html">run_models()</a></code> performs some representative binary classification modeling using <code>split_df</code> object created by <code><a href="../reference/split_by.data.frame.html">split_by()</a></code>.</p>
<p><code><a href="../reference/run_models.html">run_models()</a></code> executes the process in parallel when fitting the model. However, it is not supported in MS-Windows operating system and RStudio environment.</p>
<p>Currently supported algorithms are as follows.:</p>
<ul>
<li>logistic : logistic regression using <code>stats</code> package</li>
<li>rpart : Recursive Partitioning Trees using <code>rpart</code> package</li>
<li>ctree : Conditional Inference Trees using <code>party</code> package</li>
<li>randomForest :Classification with Random Forest using <code>randomForest</code> package</li>
<li>ranger : A Fast Implementation of Random Forests using <code>ranger</code> package</li>
<li>xgboost : Extreme Gradient Boosting using <code>xgboost</code> package</li>
</ul>
<p><code><a href="../reference/run_models.html">run_models()</a></code> returns a <code>model_df</code> class object.</p>
<p>The <code>model_df</code> class object contains the following variables.:</p>
<ul>
<li>step : character. The current stage in the classification modeling process.
<ul>
<li>For objects created with <code><a href="../reference/run_models.html">run_models()</a></code>, the value of the variable is “1.Fitted”.</li>
</ul>
</li>
<li>model_id : model identifiers</li>
<li>target : name of target variable</li>
<li>positive : positive class in target variable</li>
<li>fitted_model : list. Fitted model object by model_id’s algorithms</li>
</ul>
<div class="sourceCode" id="cb12"><html><body><pre class="r">result &lt;- train %&gt;% 
  run_models(target = "Class", positive = "malignant")
result
# A tibble: 6 x 7
  step     model_id     target is_factor positive  negative fitted_model
  &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;  &lt;lgl&gt;     &lt;chr&gt;     &lt;chr&gt;    &lt;list&gt;      
1 1.Fitted logistic     Class  TRUE      malignant benign   &lt;glm&gt;       
2 1.Fitted rpart        Class  TRUE      malignant benign   &lt;rpart&gt;     
3 1.Fitted ctree        Class  TRUE      malignant benign   &lt;BinaryTr&gt;  
4 1.Fitted randomForest Class  TRUE      malignant benign   &lt;rndmFrs.&gt;  
5 1.Fitted ranger       Class  TRUE      malignant benign   &lt;ranger&gt;    
6 1.Fitted xgboost      Class  TRUE      malignant benign   &lt;xgb.Bstr&gt;  </pre></body></html></div>
</div>
<div id="evaluate-the-model" class="section level2">
<h2 class="hasAnchor">
<a href="#evaluate-the-model" class="anchor"></a>Evaluate the model</h2>
<p>Evaluate the predictive performance of fitted models.</p>
<div id="predict-test-set-using-fitted-model-with-run_predict" class="section level3">
<h3 class="hasAnchor">
<a href="#predict-test-set-using-fitted-model-with-run_predict" class="anchor"></a>Predict test set using fitted model with <code>run_predict()</code>
</h3>
<p><code><a href="../reference/run_predict.html">run_predict()</a></code> predict the test set using <code>model_df</code> class fitted by <code><a href="../reference/run_models.html">run_models()</a></code>.</p>
<p><code><a href="../reference/run_predict.html">run_predict ()</a></code> is executed in parallel when predicting by model. However, it is not supported in MS-Windows operating system and RStudio environment.</p>
<p>The <code>model_df</code> class object contains the following variables.:</p>
<ul>
<li>step : character. The current stage in the classification modeling process.
<ul>
<li>For objects created with <code><a href="../reference/run_predict.html">run_predict()</a></code>, the value of the variable is “2.Predicted”.</li>
</ul>
</li>
<li>model_id : character. Type of fit model.</li>
<li>target : character. Name of target variable.</li>
<li>positive : character. Level of positive class of binary classification.</li>
<li>fitted_model : list. Fitted model object by model_id’s algorithms.</li>
<li>predicted : result of predcit by each models</li>
</ul>
<div class="sourceCode" id="cb13"><html><body><pre class="r">pred &lt;- result %&gt;%
  run_predict(test)
pred
# A tibble: 6 x 8
  step     model_id   target is_factor positive  negative fitted_model predicted
  &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;  &lt;lgl&gt;     &lt;chr&gt;     &lt;chr&gt;    &lt;list&gt;       &lt;list&gt;   
1 2.Predi… logistic   Class  TRUE      malignant benign   &lt;glm&gt;        &lt;fct [21…
2 2.Predi… rpart      Class  TRUE      malignant benign   &lt;rpart&gt;      &lt;fct [21…
3 2.Predi… ctree      Class  TRUE      malignant benign   &lt;BinaryTr&gt;   &lt;fct [21…
4 2.Predi… randomFor… Class  TRUE      malignant benign   &lt;rndmFrs.&gt;   &lt;fct [21…
5 2.Predi… ranger     Class  TRUE      malignant benign   &lt;ranger&gt;     &lt;fct [21…
6 2.Predi… xgboost    Class  TRUE      malignant benign   &lt;xgb.Bstr&gt;   &lt;fct [21…</pre></body></html></div>
</div>
<div id="calculate-the-performance-metric-with-run_performance" class="section level3">
<h3 class="hasAnchor">
<a href="#calculate-the-performance-metric-with-run_performance" class="anchor"></a>Calculate the performance metric with <code>run_performance()</code>
</h3>
<p><code><a href="../reference/run_performance.html">run_performance()</a></code> calculate the performance metric of <code>model_df</code> class predicted by <code><a href="../reference/run_predict.html">run_predict()</a></code>.</p>
<p><code><a href="../reference/run_performance.html">run_performance ()</a></code> is performed in parallel when calculating the performance evaluation metrics However, it is not supported in MS-Windows operating system and RStudio environment.</p>
<p>The <code>model_df</code> class object contains the following variables.:</p>
<ul>
<li>step : character. The current stage in the classification modeling process.
<ul>
<li>For objects created with <code><a href="../reference/run_performance.html">run_performance()</a></code>, the value of the variable is “3.Performanced”.</li>
</ul>
</li>
<li>model_id : character. Type of fit model.</li>
<li>target : character. Name of target variable.</li>
<li>positive : character. Level of positive class of binary classification.</li>
<li>fitted_model : list. Fitted model object by model_id’s algorithms</li>
<li>predicted : list. Predicted value by individual model. Each value has a predict_class class object.</li>
<li>performance : list. Calculate metrics by individual model. Each value has a numeric vector.</li>
</ul>
<div class="sourceCode" id="cb14"><html><body><pre class="r"># Calculate performace metrics.
perf &lt;- run_performance(pred)
perf
# A tibble: 6 x 7
  step          model_id     target positive fitted_model predicted  performance
  &lt;chr&gt;         &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;    &lt;list&gt;       &lt;list&gt;     &lt;list&gt;     
1 3.Performanc… logistic     Class  maligna… &lt;glm&gt;        &lt;fct [210… &lt;dbl [15]&gt; 
2 3.Performanc… rpart        Class  maligna… &lt;rpart&gt;      &lt;fct [210… &lt;dbl [15]&gt; 
3 3.Performanc… ctree        Class  maligna… &lt;BinaryTr&gt;   &lt;fct [210… &lt;dbl [15]&gt; 
4 3.Performanc… randomForest Class  maligna… &lt;rndmFrs.&gt;   &lt;fct [210… &lt;dbl [15]&gt; 
5 3.Performanc… ranger       Class  maligna… &lt;ranger&gt;     &lt;fct [210… &lt;dbl [15]&gt; 
6 3.Performanc… xgboost      Class  maligna… &lt;xgb.Bstr&gt;   &lt;fct [210… &lt;dbl [15]&gt; </pre></body></html></div>
<p>The performance variable contains a list object, which contains 15 performance metrics:</p>
<ul>
<li>ZeroOneLoss : Normalized Zero-One Loss(Classification Error Loss).</li>
<li>Accuracy : Accuracy.</li>
<li>Precision : Precision.</li>
<li>Recall : Recall.</li>
<li>Sensitivity : Sensitivity.</li>
<li>Specificity : Specificity.</li>
<li>F1_Score : F1 Score.</li>
<li>Fbeta_Score : F-Beta Score.</li>
<li>LogLoss : Log loss / Cross-Entropy Loss.</li>
<li>AUC : Area Under the Receiver Operating Characteristic Curve (ROC AUC).</li>
<li>Gini : Gini Coefficient.</li>
<li>PRAUC : Area Under the Precision-Recall Curve (PR AUC).</li>
<li>LiftAUC : Area Under the Lift Chart.</li>
<li>GainAUC : Area Under the Gain Chart.</li>
<li>KS_Stat : Kolmogorov-Smirnov Statistic.</li>
</ul>
<div class="sourceCode" id="cb15"><html><body><pre class="r"># Performance by analytics models
performance &lt;- perf$performance
names(performance) &lt;- perf$model_id
performance
$logistic
ZeroOneLoss    Accuracy   Precision      Recall Sensitivity Specificity 
 0.06666667  0.93333333  0.94366197  0.87012987  0.87012987  0.96992481 
   F1_Score Fbeta_Score     LogLoss         AUC        Gini       PRAUC 
 0.90540541  0.90540541  1.81712706  0.94038668  0.93672493  0.11492261 
    LiftAUC     GainAUC     KS_Stat 
 1.23133240  0.77891156 85.30416951 

$rpart
ZeroOneLoss    Accuracy   Precision      Recall Sensitivity Specificity 
 0.06666667  0.93333333  0.87058824  0.96103896  0.96103896  0.91729323 
   F1_Score Fbeta_Score     LogLoss         AUC        Gini       PRAUC 
 0.91358025  0.91358025  0.24117861  0.94463431  0.91407089  0.91286644 
    LiftAUC     GainAUC     KS_Stat 
 1.98861751  0.78160173 88.38004101 

$ctree
ZeroOneLoss    Accuracy   Precision      Recall Sensitivity Specificity 
  0.0952381   0.9047619   0.8607595   0.8831169   0.8831169   0.9172932 
   F1_Score Fbeta_Score     LogLoss         AUC        Gini       PRAUC 
  0.8717949   0.8717949   1.3176530   0.9341373   0.8996192   0.7010453 
    LiftAUC     GainAUC     KS_Stat 
  1.7414323   0.7749536  80.6561859 

$randomForest
ZeroOneLoss    Accuracy   Precision      Recall Sensitivity Specificity 
 0.03809524  0.96190476  0.91566265  0.98701299  0.98701299  0.94736842 
   F1_Score Fbeta_Score     LogLoss         AUC        Gini       PRAUC 
 0.95000000  0.95000000  0.15656563  0.98252124  0.96484718  0.75098856 
    LiftAUC     GainAUC     KS_Stat 
 1.78549834  0.80559678 93.98496241 

$ranger
ZeroOneLoss    Accuracy   Precision      Recall Sensitivity Specificity 
 0.03809524  0.96190476  0.91566265  0.98701299  0.98701299  0.94736842 
   F1_Score Fbeta_Score     LogLoss         AUC        Gini       PRAUC 
 0.95000000  0.95000000  0.12133005  0.98886827  0.97773655  0.87237251 
    LiftAUC     GainAUC     KS_Stat 
 1.89198172  0.80961657 94.73684211 

$xgboost
ZeroOneLoss    Accuracy   Precision      Recall Sensitivity Specificity 
 0.04285714  0.95714286  0.92500000  0.96103896  0.96103896  0.95488722 
   F1_Score Fbeta_Score     LogLoss         AUC        Gini       PRAUC 
 0.94267516  0.94267516  0.14537516  0.98750122  0.97480715  0.94957501 
    LiftAUC     GainAUC     KS_Stat 
 1.98323764  0.80875077 92.34449761 </pre></body></html></div>
<p>If you change the list object to tidy format, you’ll see the following at a glance:</p>
<div class="sourceCode" id="cb16"><html><body><pre class="r"># Convert to matrix for compare performace.
sapply(performance, "c")
               logistic       rpart      ctree randomForest      ranger
ZeroOneLoss  0.06666667  0.06666667  0.0952381   0.03809524  0.03809524
Accuracy     0.93333333  0.93333333  0.9047619   0.96190476  0.96190476
Precision    0.94366197  0.87058824  0.8607595   0.91566265  0.91566265
Recall       0.87012987  0.96103896  0.8831169   0.98701299  0.98701299
Sensitivity  0.87012987  0.96103896  0.8831169   0.98701299  0.98701299
Specificity  0.96992481  0.91729323  0.9172932   0.94736842  0.94736842
F1_Score     0.90540541  0.91358025  0.8717949   0.95000000  0.95000000
Fbeta_Score  0.90540541  0.91358025  0.8717949   0.95000000  0.95000000
LogLoss      1.81712706  0.24117861  1.3176530   0.15656563  0.12133005
AUC          0.94038668  0.94463431  0.9341373   0.98252124  0.98886827
Gini         0.93672493  0.91407089  0.8996192   0.96484718  0.97773655
PRAUC        0.11492261  0.91286644  0.7010453   0.75098856  0.87237251
LiftAUC      1.23133240  1.98861751  1.7414323   1.78549834  1.89198172
GainAUC      0.77891156  0.78160173  0.7749536   0.80559678  0.80961657
KS_Stat     85.30416951 88.38004101 80.6561859  93.98496241 94.73684211
                xgboost
ZeroOneLoss  0.04285714
Accuracy     0.95714286
Precision    0.92500000
Recall       0.96103896
Sensitivity  0.96103896
Specificity  0.95488722
F1_Score     0.94267516
Fbeta_Score  0.94267516
LogLoss      0.14537516
AUC          0.98750122
Gini         0.97480715
PRAUC        0.94957501
LiftAUC      1.98323764
GainAUC      0.80875077
KS_Stat     92.34449761</pre></body></html></div>
<p><code><a href="../reference/compare_performance.html">compare_performance()</a></code> return a list object(results of compared model performance). and list has the following components:</p>
<ul>
<li>recommend_model : character. The name of the model that is recommended as the best among the various models.</li>
<li>top_count : numeric. The number of best performing performance metrics by model.</li>
<li>mean_rank : numeric. Average of ranking individual performance metrics by model.</li>
<li>top_metric : list. The name of the performance metric with the best performance on individual performance metrics by model.</li>
</ul>
<p>In this example, <code><a href="../reference/compare_performance.html">compare_performance()</a></code> recommend the <strong>“ranger”</strong> model.</p>
<div class="sourceCode" id="cb17"><html><body><pre class="r"># Compaire the Performance metrics of each model
comp_perf &lt;- compare_performance(pred)
comp_perf
$recommend_model
[1] "ranger"

$top_metric_count
    logistic        rpart        ctree randomForest       ranger      xgboost 
           2            1            0            4            9            1 

$mean_rank
    logistic        rpart        ctree randomForest       ranger      xgboost 
    4.538462     3.923077     5.653846     2.692308     1.846154     2.346154 

$top_metric
$top_metric$logistic
[1] "Precision"   "Specificity"

$top_metric$rpart
[1] "LiftAUC"

$top_metric$ctree
NULL

$top_metric$randomForest
[1] "ZeroOneLoss" "Accuracy"    "Recall"      "F1_Score"   

$top_metric$ranger
[1] "ZeroOneLoss" "Accuracy"    "Recall"      "F1_Score"    "LogLoss"    
[6] "AUC"         "Gini"        "GainAUC"     "KS_Stat"    

$top_metric$xgboost
[1] "PRAUC"</pre></body></html></div>
</div>
<div id="plot-the-roc-curve-with-plot_performance" class="section level3">
<h3 class="hasAnchor">
<a href="#plot-the-roc-curve-with-plot_performance" class="anchor"></a>Plot the ROC curve with <code>plot_performance()</code>
</h3>
<p><code><a href="../reference/compare_performance.html">compare_performance()</a></code> plot ROC curve.</p>
<div class="sourceCode" id="cb18"><html><body><pre class="r"><span class="co"># Plot ROC curve</span>
<span class="fu"><a href="../reference/plot_performance.html">plot_performance</a></span>(<span class="no">pred</span>)</pre></body></html></div>
<p><img src="modeling_files/figure-html/ROC-1.png" width="672"></p>
</div>
<div id="tunning-the-cut-off" class="section level3">
<h3 class="hasAnchor">
<a href="#tunning-the-cut-off" class="anchor"></a>Tunning the cut-off</h3>
<p>In general, if the prediction probability is greater than 0.5 in the binary classification model, it is predicted as <code>positive class</code>. In other words, 0.5 is used for the cut-off value. This applies to most model algorithms. However, in some cases, the performance can be tuned by changing the cut-off value.</p>
<p><code><a href="../reference/plot_cutoff.html">plot_cutoff ()</a></code> visualizes a plot to select the cut-off value, and returns the cut-off value.</p>
<div class="sourceCode" id="cb19"><html><body><pre class="r"><span class="no">pred_best</span> <span class="kw">&lt;-</span> <span class="no">pred</span> <span class="kw">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span>(<span class="no">model_id</span> <span class="kw">==</span> <span class="no">comp_perf</span>$<span class="no">recommend_model</span>) <span class="kw">%&gt;%</span>
  <span class="fu">select</span>(<span class="no">predicted</span>) <span class="kw">%&gt;%</span>
  <span class="no">pull</span> <span class="kw">%&gt;%</span>
  <span class="no">.</span><span class="kw">[[</span><span class="fl">1</span>]] <span class="kw">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span>(<span class="st">"pred_prob"</span>)

<span class="no">cutoff</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/plot_cutoff.html">plot_cutoff</a></span>(<span class="no">pred_best</span>, <span class="no">test</span>$<span class="no">Class</span>, <span class="st">"malignant"</span>, <span class="kw">type</span> <span class="kw">=</span> <span class="st">"mcc"</span>)</pre></body></html></div>
<p><img src="modeling_files/figure-html/cutoff-1.png" width="672"></p>
<div class="sourceCode" id="cb20"><html><body><pre class="r">cutoff
[1] 0.46

cutoff2 &lt;- plot_cutoff(pred_best, test$Class, "malignant", type = "density")</pre></body></html></div>
<p><img src="modeling_files/figure-html/cutoff-2.png" width="672"></p>
<div class="sourceCode" id="cb21"><html><body><pre class="r">cutoff2
[1] 0.8239

cutoff3 &lt;- plot_cutoff(pred_best, test$Class, "malignant", type = "prob")</pre></body></html></div>
<p><img src="modeling_files/figure-html/cutoff-3.png" width="672"></p>
<div class="sourceCode" id="cb22"><html><body><pre class="r">cutoff3
[1] 0.46</pre></body></html></div>
</div>
<div id="performance-comparison-between-prediction-and-tuned-cut-off-with-performance_metric" class="section level3">
<h3 class="hasAnchor">
<a href="#performance-comparison-between-prediction-and-tuned-cut-off-with-performance_metric" class="anchor"></a>Performance comparison between prediction and tuned cut-off with <code>performance_metric()</code>
</h3>
<p>Compare the performance of the original prediction with that of the tuned cut-off. Compare the cut-off with the non-cut model for the model with the best performance <code>comp_perf$recommend_model</code>.</p>
<div class="sourceCode" id="cb23"><html><body><pre class="r">comp_perf$recommend_model
[1] "ranger"

# extract predicted probability
idx &lt;- which(pred$model_id == comp_perf$recommend_model)
pred_prob &lt;- attr(pred$predicted[[idx]], "pred_prob")

# or, extract predicted probability using dplyr
pred_prob &lt;- pred %&gt;% 
  filter(model_id == comp_perf$recommend_model) %&gt;% 
  select(predicted) %&gt;% 
  pull %&gt;% 
  "[["(1) %&gt;% 
  attr("pred_prob")

# predicted probability
pred_prob  
  [1] 8.175675e-01 5.333333e-04 8.204278e-01 9.898659e-01 4.687683e-01
  [6] 7.733556e-01 9.523635e-01 7.278444e-01 7.041270e-03 8.290135e-01
 [11] 9.875468e-01 5.333333e-04 0.000000e+00 6.376302e-01 0.000000e+00
 [16] 9.389992e-01 0.000000e+00 6.332754e-01 0.000000e+00 1.435349e-01
 [21] 9.883016e-02 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00
 [26] 5.855357e-01 9.939389e-01 9.368698e-01 9.867762e-01 9.984500e-01
 [31] 8.119913e-03 7.823302e-01 5.010000e-02 0.000000e+00 0.000000e+00
 [36] 8.573444e-01 1.142556e-01 9.419881e-01 9.445317e-02 0.000000e+00
 [41] 0.000000e+00 8.751516e-01 2.381667e-02 3.714865e-01 9.781746e-01
 [46] 3.484127e-03 9.218381e-01 0.000000e+00 0.000000e+00 9.961838e-02
 [51] 8.134683e-01 0.000000e+00 0.000000e+00 9.890254e-01 9.858556e-01
 [56] 0.000000e+00 2.631579e-05 0.000000e+00 9.837492e-01 2.631579e-05
 [61] 0.000000e+00 9.965175e-01 0.000000e+00 2.631579e-05 1.000000e+00
 [66] 9.985429e-01 9.957810e-01 9.811508e-01 9.051016e-01 9.979119e-01
 [71] 9.987778e-01 9.958198e-01 9.982222e-01 3.309452e-01 0.000000e+00
 [76] 9.944857e-01 0.000000e+00 1.000000e+00 9.962794e-01 9.809968e-01
 [81] 9.878190e-01 9.769587e-01 7.316468e-01 0.000000e+00 9.595897e-01
 [86] 9.996667e-01 0.000000e+00 0.000000e+00 0.000000e+00 2.589952e-01
 [91] 2.612516e-01 0.000000e+00 0.000000e+00 2.631579e-05 9.927865e-01
 [96] 9.943381e-01 2.751349e-02 0.000000e+00 9.604619e-01 9.627357e-01
[101] 0.000000e+00 9.856627e-01 0.000000e+00 3.193968e-02 5.087190e-01
[106] 7.886794e-01 0.000000e+00 7.619444e-02 9.886921e-01 2.631579e-05
[111] 0.000000e+00 0.000000e+00 3.420444e-01 0.000000e+00 0.000000e+00
[116] 0.000000e+00 9.640802e-01 2.749730e-01 4.483889e-02 1.000000e+00
[121] 0.000000e+00 9.942111e-01 0.000000e+00 1.127960e-01 0.000000e+00
[126] 3.481032e-02 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00
[131] 8.652619e-02 1.000000e+00 0.000000e+00 9.990952e-01 2.044651e-01
[136] 9.490833e-01 8.885841e-01 9.825048e-01 0.000000e+00 9.796865e-01
[141] 1.233333e-03 9.973952e-01 2.000000e-04 1.000000e+00 9.605738e-01
[146] 9.806143e-01 2.631579e-05 0.000000e+00 9.962810e-01 2.631579e-05
[151] 0.000000e+00 9.951873e-01 0.000000e+00 9.948183e-01 2.631579e-05
[156] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.000000e-04
[161] 2.625000e-02 0.000000e+00 4.000000e-04 2.631579e-05 0.000000e+00
[166] 7.870476e-02 0.000000e+00 0.000000e+00 0.000000e+00 8.687365e-01
[171] 9.910571e-01 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00
[176] 1.235317e-02 0.000000e+00 9.348000e-01 9.942659e-01 5.974603e-03
[181] 0.000000e+00 0.000000e+00 8.078373e-01 9.918444e-01 0.000000e+00
[186] 9.993143e-01 6.666667e-04 0.000000e+00 7.826278e-01 0.000000e+00
[191] 0.000000e+00 0.000000e+00 4.150000e-03 0.000000e+00 6.918975e-02
[196] 0.000000e+00 0.000000e+00 0.000000e+00 6.418762e-01 0.000000e+00
[201] 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00
[206] 6.185714e-03 9.206389e-01 2.381667e-02 0.000000e+00 9.744698e-01

# compaire Accuracy
performance_metric(pred_prob, test$Class, "malignant", "Accuracy")
[1] 0.9619048
performance_metric(pred_prob, test$Class, "malignant", "Accuracy",
                   cutoff = cutoff)
[1] 0.9666667

# compaire Confusion Matrix
performance_metric(pred_prob, test$Class, "malignant", "ConfusionMatrix")
           actual
predict     benign malignant
  benign       126         1
  malignant      7        76
performance_metric(pred_prob, test$Class, "malignant", "ConfusionMatrix", 
                   cutoff = cutoff)
           actual
predict     benign malignant
  benign       126         0
  malignant      7        77

# compaire F1 Score
performance_metric(pred_prob, test$Class, "malignant", "F1_Score")
[1] 0.95
performance_metric(pred_prob, test$Class,  "malignant", "F1_Score", 
                   cutoff = cutoff)
[1] 0.9565217
performance_metric(pred_prob, test$Class,  "malignant", "F1_Score", 
                   cutoff = cutoff2)
[1] 0.9103448</pre></body></html></div>
<p>If the performance of the tuned cut-off is good, use it as a cut-off to predict positives.</p>
</div>
</div>
<div id="predict" class="section level2">
<h2 class="hasAnchor">
<a href="#predict" class="anchor"></a>Predict</h2>
<p>If you have selected a good model from several models, then perform the prediction with that model.</p>
<div id="create-data-set-for-predict" class="section level3">
<h3 class="hasAnchor">
<a href="#create-data-set-for-predict" class="anchor"></a>Create data set for predict</h3>
<p>Create sample data for predicting by extracting 100 samples from the data set used in the previous under sampling example.</p>
<div class="sourceCode" id="cb24"><html><body><pre class="r">data_pred &lt;- train_under %&gt;% 
  cleanse 
── Checking unique value ─────────────────────────── unique value is one ──
No variables that unique value is one.

── Checking unique rate ─────────────────────────────── high unique rate ──
remove variables with high unique rate
● Id = 322(0.981707317073171)

── Checking character variables ─────────────────────── categorical data ──
No character variables.

set.seed(1234L)
data_pred &lt;- data_pred %&gt;% 
  nrow %&gt;% 
  seq %&gt;% 
  sample(size = 50) %&gt;% 
  data_pred[., ]</pre></body></html></div>
</div>
<div id="predict-with-alookr-and-dplyr" class="section level3">
<h3 class="hasAnchor">
<a href="#predict-with-alookr-and-dplyr" class="anchor"></a>Predict with alookr and dplyr</h3>
<p>Do a predict using the <code>dplyr</code> package. The last <code><a href="https://rdrr.io/r/base/factor.html">factor()</a></code> function eliminates unnecessary information.</p>
<div class="sourceCode" id="cb25"><html><body><pre class="r">pred_actual &lt;- pred %&gt;%
  filter(model_id == comp_perf$recommend_model) %&gt;% 
  run_predict(data_pred) %&gt;% 
  select(predicted) %&gt;% 
  pull %&gt;% 
  "[["(1) %&gt;% 
  factor()

pred_actual
 [1] malignant benign    benign    benign    malignant malignant malignant
 [8] benign    malignant malignant malignant benign    malignant benign   
[15] malignant benign    benign    benign    malignant benign    malignant
[22] malignant benign    benign    malignant malignant malignant malignant
[29] benign    benign    malignant benign    malignant malignant malignant
[36] benign    malignant benign    malignant benign    malignant benign   
[43] benign    malignant malignant benign    benign    benign    benign   
[50] benign   
Levels: benign malignant</pre></body></html></div>
<p>If you want to predict by cut-off, specify the <code>cutoff</code> argument in the <code><a href="../reference/run_predict.html">run_predict()</a></code> function as follows.:</p>
<p>In the example, there is no difference between the results of using cut-off and not.</p>
<div class="sourceCode" id="cb26"><html><body><pre class="r">pred_actual2 &lt;- pred %&gt;%
  filter(model_id == comp_perf$recommend_model) %&gt;% 
  run_predict(data_pred, cutoff) %&gt;% 
  select(predicted) %&gt;% 
  pull %&gt;% 
  "[["(1) %&gt;% 
  factor()

pred_actual2
 [1] malignant benign    benign    benign    malignant malignant malignant
 [8] benign    malignant malignant malignant benign    malignant benign   
[15] malignant benign    benign    benign    malignant benign    malignant
[22] malignant benign    benign    malignant malignant malignant malignant
[29] benign    benign    malignant benign    malignant malignant malignant
[36] benign    malignant benign    malignant benign    malignant benign   
[43] benign    malignant malignant benign    benign    benign    benign   
[50] benign   
Levels: benign malignant

sum(pred_actual != pred_actual2)
[1] 0</pre></body></html></div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Choonghyun Ryu.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
